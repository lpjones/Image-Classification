{"cells":[{"cell_type":"markdown","id":"b4fcbbf9","metadata":{"id":"b4fcbbf9"},"source":["# Phase 1 - (Convolutional) Neural Networks\n","\n","Please follow the notebook in order. Make sure to add code where indicated by `''' TODO '''` or `# YOUR CODE HERE`. Ensure your notebook is easy to follow. All written report answers should be provided in the notebook itself.\n","\n","You may find [this](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html) pytorch tutorial helpful."]},{"cell_type":"code","execution_count":null,"id":"6dc76898","metadata":{"id":"6dc76898"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torchvision.datasets as datasets\n","import torchvision.transforms as transforms\n","\n","import matplotlib.pyplot as plt\n","import numpy as np"]},{"cell_type":"markdown","source":["## 1. Loading & Visualizing Data\n","\n","Please use MNIST for this Phase. MNIST is a digit classification dataset, with greyscale 28x28 images, and 10 classes (numbers 0-9). See [documentaion.](https://pytorch.org/vision/0.15/generated/torchvision.datasets.MNIST.html) You can also see the MNIST_Tutorial.ipynb\n","\n","Please complete loading the data.\n","\n","Please also complete `show_imgs()`. Function should input the dataloader, and show random 10 images and their labels as title to plot. Make sure the 10 images are organized in a grid or format or with matplotlib axis."],"metadata":{"id":"LCRrCFrXTzpE"},"id":"LCRrCFrXTzpE"},{"cell_type":"code","source":["train_data = ''' TODO '''\n","\n","test_data = ''' TODO '''\n","\n","batch_size = 32\n","\n","train_loader = ''' TODO '''\n","\n","test_loader = ''' TODO '''"],"metadata":{"id":"RZcVXNWTT6nJ"},"id":"RZcVXNWTT6nJ","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Function should input the dataloader, and show random 10 images and their labels as title to plot\n","def show_imgs():\n","    ''' TODO '''"],"metadata":{"id":"QA7akV67UIdR"},"id":"QA7akV67UIdR","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"eefd27b6","metadata":{"id":"eefd27b6"},"source":["## 2. Utility Functions\n","\n","Please complete `train()` and `plot_learning_curves()` functions. `test_accuracy()` has already been provided to you."]},{"cell_type":"code","execution_count":null,"id":"5f8c1f20","metadata":{"id":"5f8c1f20"},"outputs":[],"source":["def test_accuracy(model, test_loader, input_size, device):\n","    model.to(device)\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for test_data in test_loader:\n","            images, labels = test_data[0].cuda(), test_data[1].cuda()\n","            images = images.view(-1, input_size)\n","            outputs = net(images)\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","    print('Accuracy: %d %%' % (100 * correct / total))\n"]},{"cell_type":"markdown","id":"1e7f84cf","metadata":{"id":"1e7f84cf"},"source":["### 2.1 Train Function\n","Please refer to the train function in `MNIST_Classifier.ipynb` to complete this function. You will need to store the store the loss and accuracies per iteration to plot. Please print the loss, accuracy and time taken for training each epoch."]},{"cell_type":"code","execution_count":null,"id":"04f8929f","metadata":{"id":"04f8929f"},"outputs":[],"source":["def train(model, loss_fn, optimizer, train_loader, batch_size, num_epochs, device):\n","    ''' TODO '''"]},{"cell_type":"markdown","id":"ab00c312","metadata":{"id":"ab00c312"},"source":["### 2.2 Plot Learning Curves Function\n","Plot the loss and accuracies from training"]},{"cell_type":"code","execution_count":null,"id":"77d3a47d","metadata":{"id":"77d3a47d"},"outputs":[],"source":["def plot_learning_curve(''' TODO '''):\n","    ''' TODO '''"]},{"cell_type":"markdown","source":["## 3) Define CNNs\n","\n","A 1-Layer Architecture is already defined for you (`Net`) as a reference. Please complete the definitions of the 2-Layer CNN (`Net2`), 5-Layer CNN (`Net5`). The network architecture definitions are provided to you. You must calculate some dimensions yourself.\n","\n","**NOTE:** For now, please use ReLU activation. You will experiment with other activations in Section 5."],"metadata":{"id":"Zul5dm0YWA06"},"id":"Zul5dm0YWA06"},{"cell_type":"code","source":["class Net(nn.Module):\n","    def __init__(self, input_size, num_classes):\n","        super(Net,self).__init__()\n","        self.fc1 = nn.Linear(input_size, 500)\n","        self.relu = nn.ReLU()\n","        self.fc2 = nn.Linear(500, num_classes)\n","\n","    def forward(self,x):\n","        out = self.fc1(x)\n","        out = self.relu(out)\n","        out = self.fc2(out)\n","        return out"],"metadata":{"id":"09GKicADXE30"},"id":"09GKicADXE30","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 3.1) 2-Layer CNN\n","Complete `Net2` class.\n","\n"," Network Architecture:\n","* ***Layer 1 (Input)***: Convolutional; input channel = 1, output channel = 20, kernel size = 3, step size = 1.\n","* ***Layer 2 (Output)***: Fully connected; input dimension = < you find out >, output dimension = < you find out >."],"metadata":{"id":"5guirZljXK6R"},"id":"5guirZljXK6R"},{"cell_type":"code","source":["# Define 2-Layer Network\n","class Net2(nn.Module):\n","    ''' TODO '''"],"metadata":{"id":"hKKB698vXaGJ"},"id":"hKKB698vXaGJ","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"971035a3","metadata":{"id":"971035a3"},"source":["## 4) Train and Evaluate\n","\n","### 4.1) Here, you must test your utility functions (`train()` and `plot_learning_curves()`)with the 1-Layer Model. Please at this stage ensure your utility functions are working correctly.\n","\n","**NOTE**: You can repeatedly use this below code black in Section 5 to run experiments, while making changes to the hyperparameters as requested."]},{"cell_type":"code","execution_count":null,"id":"efe0492a","metadata":{"id":"efe0492a"},"outputs":[],"source":["# Define Parameters\n","input_size = ''' TODO ''''\n","num_classes = ''' TODO '''\n","lr = 0.01\n","num_epochs = 10\n","\n","# Instantiate 1-Layer Model\n","net = Net(input_size, num_classes)\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","net.to(device)\n","\n","# Define Loss func and Optimizer\n","loss_function = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n","\n","# Train Model\n","train(''' TODO ''')\n","\n","# Plot Learning Curves\n","plot_learning_curve(''' TODO ''')\n","\n","# Evaluate on Test Set\n","test_accuracy(model=net, test_loader=test_loader, input_size=input_size)"]},{"cell_type":"markdown","source":["### 4.2) Please also train your 2-Layer network to ensure it is working properly."],"metadata":{"id":"6PvxFRj7hmOm"},"id":"6PvxFRj7hmOm"},{"cell_type":"code","source":["# Define Parameters\n","input_size = ''' TODO ''''\n","num_classes = ''' TODO '''\n","lr = 0.01\n","num_epochs = 10\n","\n","# Instantiate 1-Layer Model\n","net = Net2(''' TODO ''')\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","net.to(device)\n","\n","# Define Loss func and Optimizer\n","loss_function = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n","\n","# Train Model\n","train(''' TODO ''')\n","\n","# Plot Learning Curves\n","plot_learning_curve(''' TODO ''')\n","\n","# Evaluate on Test Set\n","test_accuracy(model=net, test_loader=test_loader, input_size=input_size)"],"metadata":{"id":"dEKJgrKPhiWS"},"id":"dEKJgrKPhiWS","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 5) Experiments and Reporting\n","\n","In this section you will use your utility functioins and model definitons from before, and test for different scenarios. There are report questions you must answer for all sections below. Please use the loss, accuracy, and learning curves to help answer questions.\n","\n","**NOTE:** In this section we will only change different parameters, so you can call most of your functions from previous sections. Any modifications needed in code asked by the questions in Section 5, please add them in the code sections indicated by `# YOUR CODE HERE`"],"metadata":{"id":"O9m0OClDa1rV"},"id":"O9m0OClDa1rV"},{"cell_type":"markdown","source":["### 5.1) Learning Curves\n","\n","#### **Q 5.1) What is a Learning curve and why is it useful? You can refer to learning curves you have plotted in Section 4.**\n","\n","---"],"metadata":{"id":"HM3UP2xFbefW"},"id":"HM3UP2xFbefW"},{"cell_type":"markdown","source":["### 5.1) Learning Rates\n","\n","Please plot the curves for three separate training instances with learning rates of 2e-3, 3e-4, 5e-2. Use the 2-Layer CNN.\n","\n","#### **Q 5.2) For each learning rate, explain if the model is underfitting, overfitting, or is training well. Explain the difference between high learning rates and low learning rates in terms of the optimization process.**"],"metadata":{"id":"U2DR3-0JbT4a"},"id":"U2DR3-0JbT4a"},{"cell_type":"code","execution_count":null,"id":"305bb50d","metadata":{"id":"305bb50d"},"outputs":[],"source":["# YOUR CODE HERE"]},{"cell_type":"markdown","source":["---"],"metadata":{"id":"yL4wgOhHk5e7"},"id":"yL4wgOhHk5e7"},{"cell_type":"markdown","source":["### 5.3) Optimizer\n","The optimizer we have used before is Adam. Change the optimizer to use stochastic gradient descent (SGD), and SGD with momentum. Use 2-Layer CNN.\n","\n","#### **Q 5.3) Explain the differences in Adam and both SGD optimizations. Compare the results of each optimizer based on the learning curves.**"],"metadata":{"id":"DDte2od-cRUq"},"id":"DDte2od-cRUq"},{"cell_type":"code","source":["# YOUR CODE HERE"],"metadata":{"id":"YVVHCeFYcfEz"},"id":"YVVHCeFYcfEz","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---"],"metadata":{"id":"Ui6vWzXzk36i"},"id":"Ui6vWzXzk36i"},{"cell_type":"markdown","source":["### 5.4) Initializing Weights\n","\n","Initialize the weights to all zeros, all ones and all randomly initialized with a normal distribution. Use 2-Layer CNN.\n","\n","#### **Q 5.4) How is the training process affected when we initialize our network weights differently? Based on what you observe, give a recommendation as to how weights should be initialized. Explain your reasoning.**"],"metadata":{"id":"cP3uIiJ6chLw"},"id":"cP3uIiJ6chLw"},{"cell_type":"code","source":["# YOUR CODE HERE"],"metadata":{"id":"-AUMPVQzclSS"},"id":"-AUMPVQzclSS","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---"],"metadata":{"id":"LJ0VE4GSk2xf"},"id":"LJ0VE4GSk2xf"},{"cell_type":"markdown","source":["### 5.5) Activation Function\n","\n","Please change the relu function in the example code to a tanh function. Use 2-Layer CNN.\n","\n","#### **Q 5.5) How does changing the activation function to tanh affect the performance. Is it better or worse? Explain why.**"],"metadata":{"id":"IgW1Z3Jedfud"},"id":"IgW1Z3Jedfud"},{"cell_type":"code","source":["# YOUR CODE HERE"],"metadata":{"id":"5tlh7k2pdu2v"},"id":"5tlh7k2pdu2v","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---"],"metadata":{"id":"lKXfOx9dk1kj"},"id":"lKXfOx9dk1kj"},{"cell_type":"markdown","source":["### 5.6) Batch Size\n","\n","Please use batch size of 128, 256, 512. Use 2-Layer CNN.\n","\n","#### **Q 5.6) How does changing batch size affect the training process?**"],"metadata":{"id":"neblbElOd3So"},"id":"neblbElOd3So"},{"cell_type":"code","source":["# YOUR CODE HERE"],"metadata":{"id":"L2JwLAzJeI-T"},"id":"L2JwLAzJeI-T","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---"],"metadata":{"id":"wu1b2DtUk0X9"},"id":"wu1b2DtUk0X9"},{"cell_type":"markdown","source":["### 5.7) Different Network Architectures\n","\n","Please complete the `Net5` and `FCN` definitions. The archtiectures are defined below.\n","\n","Train `Net`, `Net2`, `Net5`, and `FCN` using batch size of 64, the best learning rate from Section 5.1, and the best optimizer froom Section 5.5\n","\n","#### **Q 5.7.1) Explain which model is better and why. Use your learning curves as well as what you know about model capacity to explain your reasoning.**\n","\n","#### **Q 5.7.2) Which model converges to a minimum faster? Why? What hyperparameters would you tune in order to get a model to converge faster?**\n","\n","#### **Q 5.7.3) Explain the purpose of the pooling layer**\n","\n","#### **Q 5.7.4)  Is it possible for a model to have a smaller final loss, even if it has worse test accuracy.**\n","\n","#### **Q 5.7.5) Explain the difference between the CNN models and FCN.**"],"metadata":{"id":"gcvYw00LeL3e"},"id":"gcvYw00LeL3e"},{"cell_type":"code","source":["# YOUR CODE HERE (NET)"],"metadata":{"id":"O9pGB6N6et6-"},"id":"O9pGB6N6et6-","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# YOUR CODE HERE (NET2)"],"metadata":{"id":"x_o_qFlafXE5"},"id":"x_o_qFlafXE5","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 5-Layer CNN\n","Similar to the 2-Layer model, make a new class ```Net5```\n","\n","* ***Layer 1 (Input)***: Convolutional, input channel = 1, output channel = 32, kernel size = 5, stride = 1, padding = 2.\n","* ***Layer 2 (Hidden 1)***: Pooling, kernel size = 2, stride = 2.\n","* ***Layer 3 (Hidden 2)***: Convolutional, input channel = < you find out> , output channel = 64, kernel size = 5, stride = 1 padding = 2.\n","* ***Layer 4 (Hidden 3)***: Fully connected, input channel = < you find out>, output channel = 1024.\n","* ***Layer 5 (Output)***: Fully connected, input channel = < you find out>, < you find out >"],"metadata":{"id":"aY4UzPLlh8WU"},"id":"aY4UzPLlh8WU"},{"cell_type":"code","source":["# YOUR CODE HERE (NET5)\n","\n","# ...\n","\n","# Define 5-Layer Network\n","class Net5(nn.Module):\n","    ''' TODO '''\n","\n","# ..."],"metadata":{"id":"ukRfDvE3fYp1"},"id":"ukRfDvE3fYp1","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### FCN\n","\n","Here we will define a Fully Connected Network `FCN` (Not a CNN).\n","\n","- **Layer 1 (Input):** Size = < you find out >\n","- **Layer 2 (Hidden 1):** 256 neurons\n","- **Layer 3 (Hidden 2):** 256 neurons\n","- **Layer 4 (Output):** Size = < you find out >"],"metadata":{"id":"P1-qz_0PiAm-"},"id":"P1-qz_0PiAm-"},{"cell_type":"code","source":["# YOUR CODE HERE (FCN)\n","\n","# ...\n","\n","# Define FCN\n","class FCN(nn.Module):\n","    ''' TODO '''\n","\n","# ..."],"metadata":{"id":"gL-7bqacfZKp"},"id":"gL-7bqacfZKp","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","\n","---\n","\n","\n","\n","---\n","\n"],"metadata":{"id":"9wlnDgI5iYCc"},"id":"9wlnDgI5iYCc"},{"cell_type":"markdown","source":["### 5.8) Batch Normalization\n","\n","Choose the model that performs the best (`Net`, `Net2`, `Net5`, `FCN`). Add batch normalization layers where you see fit. Repeat and train and plot learning curves.\n","\n","#### **Q 5.8) Explain the purpose of the batch normalization layers,and how they affect training.**\n","\n"],"metadata":{"id":"u0li_CD_fc08"},"id":"u0li_CD_fc08"},{"cell_type":"code","source":["# YOUR CODE HERE"],"metadata":{"id":"FFUnLHztfwJG"},"id":"FFUnLHztfwJG","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---"],"metadata":{"id":"YDtmMWMHksq7"},"id":"YDtmMWMHksq7"}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.11"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}